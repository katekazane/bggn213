---
title: "Class 9"
author: "Katelynn Kazane"
date: "2/8/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
##**PCA and Clustering Project**

Starting out, we need to isolate our input data. 
*note: give the input file a generic name so we can reuse our code for any file*

```{r}
fna.data <- "WisconsinCancer.csv"
wisc.df <- read.csv(fna.data)
```

Always double check that your data is correct- head() allows us to look at the first six lines of the file. 
```{r}
head(wisc.df)
```

The last row has an undefined value, and we also want to exclude diagnosis and patient IDs before we analyze all of this information. (For both ease and in the real world confidentiality).
We'll only be using data from column 3 to the next to last column.

Here we're going to look at the number of patients (rows) and features (columns/categories). 

```{r}
#number of patients
nrow(wisc.df)

#of columns/categories
ncol(wisc.df)
```

Once we know the total number of columns and rows, we can clean up the data. Taking columns 3-32 (for reasons above).

```{r}
wisc.data <- wisc.df[,3:32]
head(wisc.data)
```
If we want to get rid of columns in the middle, we can make a vector: c(4, 10, 32)


Now we want to set the row names to the patient IDs. That way we can track the patients without treating the IDs as values to be incorporated.
*note: use head() again to check your work*

```{r}
rownames(wisc.data) <- wisc.df$id
head(wisc.data)
```

Setting up an example of how to *quickly* characterize data. 

How many malignant v begnin tumors are there?
```{r}
table(wisc.df$diagnosis)
```

We want to find out how many of the columns are mean values. Therefore we have to search for the columns containing "mean".
*note: remember we're using "wisc.data"*
*note: we add the _ before mean, so that we only get mean as a single work*

```{r}
#colnames(wisc.data)
length( grep("_mean",colnames(wisc.data)) )

```

After calculating how many columns are mean values, we want to find out the names of those columns. 
*note: remember we need to reference the columns again*
```{r}
inds <- grep("_mean",colnames(wisc.data))
colnames(wisc.data)[inds]
```

**Preparing the data for Principal Component Analysis**
Before we start analysis, it's worth checking the column means and standard deviations to examine if we need to scale things. 

**Mean values**
```{r}
# we can use this <- colMeans(wisc.data). But the following is better:
round( apply(wisc.data, 2, mean), 2)
```

Note that apply(wisc.data, **2**) refers to columns. 1 would refer to rows. 

**Standard Deviations**
```{r}
round( apply(wisc.data, 2, sd), 2)
```

After looking at the means and SD, we know we need to scale the data. 
Now PCA time!

##Principal Components Analysis (PCA)

```{r}
wisc.pr <- prcomp(wisc.data, scale = TRUE)
#remember we needed to scale!

summary(wisc.pr)
```

```{r}
biplot(wisc.pr)
```
This plot is awful. We are going to fix it. 

Here's how we make our own/make it nicer:
```{r}
plot( wisc.pr$x[,1], wisc.pr$x[,2])
```

We have a graph- we want to add some details and expand on it (using the B vs M diagnosis). Ideally we'll want to color it by diagnosis. Because color differences makes visualizing data much more simple. (And pattern recognition is cool).

```{r}
wisc.df$diagnosis
```

```{r}
#wisc.df$diagnosis is the code we use to call all this data.
plot( wisc.pr$x[,1], wisc.pr$x[,2], col= wisc.df$diagnosis)
```

Time for us to really dig in to the data.

Looking at the variance for each component in the analysis. 
**We'll be making a scree plot for our PCA results**
```{r}
variance <- wisc.pr$sdev^2
#finding the TOTAL variance
pve <- round(variance/sum(variance) * 100, 2)
```

```{r}
plot(pve, type = "o")
```

Or we can also make a bar plot. This one has a very strange axis. It is called "data driven".
```{r}
# Alternative scree plot of the same data, note data driven y-axis
barplot(pve, axes = FALSE, names.arg = paste("PC", 1:length(pve)), las = 2 )
#targets side two, and uses pve to drive the values.
axis(2, round(pve))
```

##Clustering in Principal Component Space

We want to make a distance matrix and then use it to make a histogram (e.g. getting a distance matrix from the PCA results- wisc.pr$x). 
```{r}
d <- dist(wisc.pr$x[,1:2])
hc <- hclust(d, method = "ward.D2")
plot(hc)
```

How do we figure out cluster membership?
Use **cutree()**  to "clip the branches". This makes the data much more managable. 
```{r}
grp3 <- cutree(hc, k = 3)
#This returns a large vector- shows us which ID is in which clusters. So we make a table to show how many individuals are in each group. 
table(grp3)
```

Now we'll plot our PCA colored by the clusters we just made. 
```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], xlab = "PC1", ylab = "PC2", col = grp3)
```

Now we have our three groups. It'll be interesting/more informative to show the contencts of each group. This is known as **cross tabulation**
```{r}
#table(grp3, ) .... first we need to make a diagnosis vector. 
#diagnosis 

diagnosis <- wisc.df$diagnosis == "M"
table(grp3, diagnosis)
```
^^^^ This is a cross tabulation:
  We specified that M = TRUE, and r counts TRUE = 1, so the values are counting the number of patients with malignancies in each group. Since TRUE/FALSE can be added as values, we can get this final count. 
  
##Predictions
Will take information from our PCA and use it to predict diagnosis.

```{r}
new <- read.csv("new_samples.csv")
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1:2], col = wisc.df$diagnosis)
points(npc[,1], npc[,2], col=c("green","blue"), pch = 15, cex = 1.5)
```

Now we have a framework for how to analyze our large data set. We can look at past trends, and then fit new data into the existing trends.